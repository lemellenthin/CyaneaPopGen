"""
This snakefile makes k-mer spectra using a bunch of reads in a file
"""
configfile: "configcy.yaml"

target_kmers = [21]

rule all:
    input:
        expand("output/{sample}_k{thisk}.jellyfish.histo.pdf", sample = config["sample"], thisk = target_kmers),
        expand("output/{sample}_k{thisk}.freqxcov.pdf", sample = config["sample"], thisk = target_kmers),
        expand("output/{sample}_k{thisk}_jellyfish_linear_plot.png", sample = config["sample"], thisk = target_kmers),
        expand("output/{sample}_k{thisk}_jellyfish_summary.txt", sample = config["sample"], thisk = target_kmers),
        expand("output/{sample}_k{thisk}_kmc_linear_plot.png", sample = config["sample"], thisk = target_kmers),
        expand("output/{sample}_k{thisk}_kmc_summary.txt", sample = config["sample"], thisk = target_kmers),
        expand("output/{sample}_k{thisk}_sharkmer_linear_plot.png", sample = config["sample"], thisk = target_kmers),
        expand("output/{sample}_k{thisk}_sharkmer_summary.txt", sample = config["sample"], thisk = target_kmers),
        expand("output/{sample}_k{thisk}_sharkmovie/{sample}_k{thisk}.sharkmer_linear_plot.mp4", sample = config["sample"], thisk = target_kmers),
        expand("output/{sample}_k{thisk}_sharkmovie/{sample}_k{thisk}.sharkmer_genomescope_size.png", sample = config["sample"], thisk = target_kmers),
        expand("output/{sample}_k{thisk}_sharkmovie/{sample}_k{thisk}.sharkmer_genomescope_fit.png", sample = config["sample"], thisk = target_kmers),
        expand("output/{sample}_k{thisk}.sharkmer_view.html", sample = config["sample"], thisk = target_kmers),
        expand("output/{sample}_k{thisk}.sharkmer_view_genome_size.html", sample = config["sample"], thisk = target_kmers),
        "output/genome_size_report.tsv",
        "output/histogram_comparison.png",


rule process_and_count_reads:
    input:
        reads = lambda wildcards: [f"{config['base_read_dir']}{x}" for x in config["sample"][wildcards.sample]["reads"]]
    output:
        R1 = temp("data/{sample}_all_R1.fastq"),
        R2 = temp("data/{sample}_all_R2.fastq"),
        R1_paired   = temp("data/{sample}_trimmed_paired_R1.fastq"),
        R1_unpaired = temp("data/{sample}_trimmed_unpaired_R1.fastq"),
        R2_paired   = temp("data/{sample}_trimmed_paired_R2.fastq"),
        R2_unpaired = temp("data/{sample}_trimmed_unpaired_R2.fastq"),
        read_count = "output/{sample}.count",
        reads = "data/{sample}.fastq"
    params:
        sample = lambda wildcards: wildcards.sample
    threads: workflow.cores
    log: "logs/trimmomatic/trimmomatic_{sample}.log"
    shell:
        """
        
        # Multiple operations are combined into a single rule here to minimize the number of files on disk at any point in time.
        
        # Concatenate reads
        zcat {input.reads}/*R1*.fastq.gz > {output.R1}
        zcat {input.reads}/*R2*.fastq.gz > {output.R2}

        # Trim reads
        echo ">PrefixPE/1\nTACACTCTTTCCCTACACGACGCTCTTCCGATCT\n>PrefixPE/2\nGTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT" > TruSeq3-PE.fa
        trimmomatic PE \
          -threads {threads} \
          {output.R1} \
          {output.R2} \
          {output.R1_paired} \
          {output.R1_unpaired} \
          {output.R2_paired} \
          {output.R2_unpaired} \
          ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:True LEADING:15 TRAILING:15 MINLEN:50 2> {log}
        
        cat {output.R1_paired} {output.R2_paired} > {output.reads}
        
        # Count reads
        sum=0
        num_lines_raw=$(cat {output.R1} | wc -l)
        num_reads_raw=$(($num_lines_raw / 4))
        num_nucleotides_raw=$(cat {output.R1} {output.R2} | awk '{{if(NR%4==2) sum+=length($0)}} END {{print sum}}' )

        sum=0
        num_lines_trimmed=$(cat {output.R1_paired} | wc -l)
        num_reads_trimmed=$(($num_lines_trimmed / 4))
        num_nucleotides_trimmed=$(cat {output.R1_paired} {output.R2_paired} | awk '{{if(NR%4==2) sum+=length($0)}} END {{print sum}}' )

        sum=0
        num_lines_unpaired_trimmed=$(cat {output.R1_unpaired} {output.R2_unpaired} | wc -l)
        num_reads_unpaired_trimmed=$(($num_lines_unpaired_trimmed / 4))
        num_nucleotides_unpaired_trimmed=$(cat {output.R1_unpaired} {output.R2_unpaired} | awk '{{if(NR%4==2) sum+=length($0)}} END {{print sum}}' )

        echo "reads_pairs_raw\t$num_reads_raw" > {output.read_count}
        echo "nucleotides_raw\t$num_nucleotides_raw" >> {output.read_count}
        echo "reads_pairs_trimmed\t$num_reads_trimmed" >> {output.read_count}
        echo "nucleotides_trimmed\t$num_nucleotides_trimmed" >> {output.read_count}
        echo "reads_unpaired_trimmed\t$num_reads_unpaired_trimmed" >> {output.read_count}
        echo "nucleotides_unpaired_trimmed\t$num_nucleotides_unpaired_trimmed" >> {output.read_count}
        """

rule generate_sharkmer_spectrum:
    input:
        reads = "data/{sample}.fastq"
    output:
        histo = "output/{sample}_k{thisk}.sharkmer.histo",
        stats = "output/{sample}_k{thisk}.sharkmer.stats",
        final_histo = "output/{sample}_k{thisk}.sharkmer.final.histo",
    params:
        sample = lambda wildcards: wildcards.sample,
        thisk = lambda wildcards: wildcards.thisk,
        base_name = "{sample}_k{thisk}.sharkmer",
        max_reads = 1000000000
    threads: workflow.cores
    benchmark: "benchmarks/sharkmer.{sample}_k{thisk}.benchmark.txt"
    log: "logs/sharkmer.{sample}_k{thisk}.log"
    shell:
        """
        sharkmer -k {params.thisk} -n 100 -t {threads} -m {params.max_reads} -o "output/" -s {params.base_name} {input.reads} > {log} 2>&1
        """

rule generate_jellyfish_spectrum:
    input:
        reads = "data/{sample}.fastq"
    output:
        histo = "output/{sample}_k{thisk}.jellyfish.histo",
        jf = temporary("output/{sample}_k{thisk}.jf")
    params:
        sample = lambda wildcards: wildcards.sample,
        thisk = lambda wildcards: wildcards.thisk,
        maxlines = 4000000000
    threads: workflow.cores
    benchmark: "benchmarks/jellyfish.{sample}_k{thisk}.benchmark.txt"
    log: "logs/jellyfish.{sample}_k{thisk}.log"
    shell:
        """
        head -n {params.maxlines} {input.reads} | jellyfish count -C -m {params.thisk} -s 1000000000 -t {threads} /dev/fd/0 -o {output.jf}
        jellyfish histo -t {threads} {output.jf} > {output.histo}
        """

rule generate_kmc_spectrum:
    input:
        reads = "data/{sample}.fastq"
    output:
        histo = "output/{sample}k{thisk}.kmc.histo",
        reads_head = temporary("output/{sample}_k{thisk}.fastq")
    params:
        sample = lambda wildcards: wildcards.sample,
        thisk = lambda wildcards: wildcards.thisk,
        intermediate = "{sample}_k{thisk}_kmc_intermediate",
        temp = "{sample}_k{thisk}_kmc_temp",
        memorygb = 640,
        maxlines = 4000000000,
    threads: workflow.cores
    benchmark: "benchmarks/kmc.{sample}_k{thisk}.benchmark.txt"
    log: "logs/kmc.{sample}_k{thisk}.log"
    shell:
        """
        # modified from http://qb.cshl.edu/genomescope/genomescope2.0/
        mkdir {params.temp}
        head -n {params.maxlines} {input.reads} > {output.reads_head}
        kmc -k{params.thisk} -t{threads} -m{params.memorygb} -ci1 -cs10000 {output.reads_head} {params.intermediate} {params.temp}
        kmc_tools transform {params.intermediate} histogram {output.histo} -cx10000
        rm {params.intermediate}*
        rm -r {params.temp}
        """

rule compare_histograms:
    input:
        sharkmer_histo = expand("output/{sample}_k{thisk}.sharkmer.final.histo", sample=config["sample"], thisk=target_kmers),
        jellyfish_histo = expand("output/{sample}_k{thisk}.jellyfish.histo", sample=config["sample"], thisk=target_kmers),
        kmc_histo = expand("output/{sample}k{thisk}.kmc.histo", sample=config["sample"], thisk=target_kmers),
    output:
        histo_fig = "output/histogram_comparison.png",
        histo_table = "output/histogram_comparison.tsv",
    run:
        import pandas as pd
        import matplotlib.pyplot as plt
        import numpy as np

        # A dataframe to hold all the results
        all_data = []

        for this_sample in config["sample"]:
            for this_kmer in target_kmers:
                # Load the data
                df_sharkmer = pd.read_csv(f"output/{this_sample}_k{this_kmer}.sharkmer.final.histo", sep='\t', header=None, names=['count', 'sharkmer'])
                df_jellyfish = pd.read_csv(f"output/{this_sample}_k{this_kmer}.jellyfish.histo", sep='\s', header=None, names=['count', 'jellyfish'])
                df_kmc = pd.read_csv(f"output/{this_sample}k{this_kmer}.kmc.histo", sep='\t', header=None, names=['count', 'kmc'])

                # Convert all columns to integers
                df_sharkmer = df_sharkmer.astype(int)
                df_jellyfish = df_jellyfish.astype(int)
                df_kmc = df_kmc.astype(int)

                # Drop the last row of kmc since it puts surplus values in element n rather than n+1
                df_kmc = df_kmc.iloc[:-1]

                # Merge dataframes on 'count'
                df_this_sample = pd.merge(pd.merge(df_sharkmer, df_jellyfish, on='count'), df_kmc, on='count')

                # Add columns for sample and kmer
                df_this_sample['sample'] = this_sample
                df_this_sample['kmer'] = this_kmer

                all_data.append(df_this_sample)

        # Combine into a single dataframe
        df = pd.concat(all_data)

        # Write the table to output.histo_table
        df.to_csv(output.histo_table, sep='\t', index=False)

        # Plot
        fig, axs = plt.subplots(len(config["sample"]), 2, figsize=(10, 5 * len(config["sample"])))
        
        custom_names = {
            'Physalia-physalis-Pacific': 'Physalia-Guam',
            'Nanomia-Pacific': 'Nanomia-California',
            'Nanomia-bijuga-Atlantic': 'Nanomia-bijuga-North-Carolina',
        }

        for i, this_sample in enumerate(config["sample"]):
            for j, this_kmer in enumerate(target_kmers):
                sample_name = custom_names.get(this_sample, this_sample)
                df_sample_kmer = df[(df['sample'] == this_sample) & (df['kmer'] == this_kmer)]
                axs[i, 0].scatter(np.log10(df_sample_kmer['sharkmer']), np.log10(df_sample_kmer['jellyfish']), alpha=0.5)
                axs[i, 1].scatter(np.log10(df_sample_kmer['sharkmer']), np.log10(df_sample_kmer['kmc']), alpha=0.5)

                axs[i, 0].set_title(f'{sample_name}')
                axs[i, 1].set_title(f'{sample_name}')

                axs[i, 0].set_xlabel('Log10(Sharkmer)')
                axs[i, 1].set_xlabel('Log10(Sharkmer)')
                axs[i, 0].set_ylabel('Log10(Jellyfish)')
                axs[i, 1].set_ylabel('Log10(KMC)')

        plt.tight_layout()
        plt.savefig(output.histo_fig)
        plt.savefig(output.histo_fig.replace('.png', '.pdf'), format='pdf')



rule generate_freqxcov_histo:
    input:
        histo = "output/{sample}_k{thisk}.jellyfish.histo"
    output:
        freqxcov = "output/{sample}_k{thisk}.freqxcov"
    params:
        sample = lambda wildcards: wildcards.sample,
        thisk = lambda wildcards: wildcards.thisk,
    threads: 1
    shell:
        """
        awk '{{print($1, $1*$2)}}' {input.histo} > {output.freqxcov}
        """

rule generate_kmer_spectrum:
    input:
        histo = "output/{sample}_k{thisk}.jellyfish.histo"
    output:
        pdf   = "output/{sample}_k{thisk}.jellyfish.histo.pdf"
    params:
        sample = lambda wildcards: wildcards.sample,
        thisk = lambda wildcards: wildcards.thisk,
    threads: 1
    shell:
        """
        cat {input.histo} | python plot_uniq_c.py -x 15 -X 400 -d -s \
          --xlab 'coverage' --ylab 'frequency' \
          --title '{params.sample} k-{params.thisk} spectrum' \
          -o {output.pdf}
        """

rule generate_freqcov_spectrum:
    input:
        freqxcov = "output/{sample}_k{thisk}.freqxcov"
    output:
        pdf = "output/{sample}_k{thisk}.freqxcov.pdf"
    params:
        sample = lambda wildcards: wildcards.sample,
        thisk = lambda wildcards: wildcards.thisk,
    threads: 1
    shell:
        """
        cat {input.freqxcov} | python plot_uniq_c.py -x 0 -X 30 -d -s \
          --xlab 'coverage' --ylab 'frequency * coverage' \
          --title '{params.sample} k-{params.thisk} spectrum' \
          -o {output.pdf}
        """

rule run_genomescope2_jellyfish:
    """
    Just runs genomescope on the output of the last file
    """
    input:
        histo = "output/{sample}_k{thisk}.jellyfish.histo"
    output:
        plot = "output/{sample}_k{thisk}_jellyfish_linear_plot.png",
        summary = "output/{sample}_k{thisk}_jellyfish_summary.txt"
    params:
        sample = lambda wildcards: wildcards.sample,
        thisk = lambda wildcards: wildcards.thisk,
    threads: 1
    shell:
        """
        genomescope2 -i {input.histo} -o {params.sample}_k{params.thisk}_jellyfish \
          -k {params.thisk} -n {params.sample}_k{params.thisk}_jellyfish
        mv {params.sample}_k{params.thisk}_jellyfish/* output/
        rm -r {params.sample}_k{params.thisk}_jellyfish/
        """

rule run_genomescope2_kmc:
    """
    Just runs genomescope on the output of the last file
    """
    input:
        histo = "output/{sample}k{thisk}.kmc.histo"
    output:
        plot = "output/{sample}_k{thisk}_kmc_linear_plot.png",
        summary = "output/{sample}_k{thisk}_kmc_summary.txt"
    params:
        sample = lambda wildcards: wildcards.sample,
        thisk = lambda wildcards: wildcards.thisk,
    threads: 1
    shell:
        """
        genomescope2 -i {input.histo} -o {params.sample}_k{params.thisk}_kmc \
          -k {params.thisk} -n {params.sample}_k{params.thisk}_kmc
        mv {params.sample}_k{params.thisk}_kmc/* output/
        rm -r {params.sample}_k{params.thisk}_kmc/
        """

rule run_genomescope2_sharkmer:
    """
    Just runs genomescope on the output of the last file
    """
    input:
        histo = "output/{sample}_k{thisk}.sharkmer.final.histo",
    output:
        plot = "output/{sample}_k{thisk}_sharkmer_linear_plot.png",
        summary = "output/{sample}_k{thisk}_sharkmer_summary.txt"
    params:
        sample = lambda wildcards: wildcards.sample,
        thisk = lambda wildcards: wildcards.thisk,
    threads: 1
    shell:
        """
        genomescope2 -i {input.histo} -o {params.sample}_k{params.thisk}_sharkmer \
          -k {params.thisk} -n {params.sample}_k{params.thisk}_sharkmer
        mv {params.sample}_k{params.thisk}_sharkmer/* output/
        rm -r {params.sample}_k{params.thisk}_sharkmer/
        """

rule run_genomescopemovie:
    """
    Run genomescopemovie.sh from sharkmer repo.
    """
    input:
        histo = "output/{sample}_k{thisk}.sharkmer.histo",
    output:
        movie_linear =        "output/{sample}_k{thisk}_sharkmovie/{sample}_k{thisk}.sharkmer_linear_plot.mp4",
        genomescope_summary = "output/{sample}_k{thisk}_sharkmovie/{sample}_k{thisk}.sharkmer_genomescope_stats.tsv",
    params:
        sample = lambda wildcards: wildcards.sample,
        thisk = lambda wildcards: wildcards.thisk,
        movie_dir = "output/{sample}_k{thisk}_sharkmovie"
    threads: workflow.cores
    shell:
        """
        genomescopemovie.sh -i {input.histo} -o {params.movie_dir} -t {threads} -k {params.thisk}
        """

rule run_genomescopemovie_summary:
    """
    Plot results from genomescopemovie.sh
    """
    input:
        genomescope_summary = "output/{sample}_k{thisk}_sharkmovie/{sample}_k{thisk}.sharkmer_genomescope_stats.tsv",
    output:
        genomescope_size_png = "output/{sample}_k{thisk}_sharkmovie/{sample}_k{thisk}.sharkmer_genomescope_size.png",
        genomescope_fit_png = "output/{sample}_k{thisk}_sharkmovie/{sample}_k{thisk}.sharkmer_genomescope_fit.png",
    params:
        sample = lambda wildcards: wildcards.sample,
        thisk = lambda wildcards: wildcards.thisk,
    log: "logs/genomescopemovie_summary.{sample}_k{thisk}.log"
    run:
        import pandas as pd
        import matplotlib
        matplotlib.use('Agg')  # Use a non-interactive backend suitable for use in scripts, avoids UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
        import matplotlib.pyplot as plt

        input_file = input.genomescope_summary 
        sample = params.sample
        thisk = params.thisk

        print(f"Input file: {input_file}")
        # Read the data
        df = pd.read_csv(input_file, sep="\t", index_col="Index")

        # Create the plot
        plt.figure(figsize=(10,6))
        plt.plot(df['Genome Haploid Length min']/1000000, label='min')
        plt.plot(df['Genome Haploid Length max']/1000000, label='max')

        # Add title and labels
        plt.title(f'Genome Length {sample}_k{thisk}')
        plt.xlabel('Sample')
        plt.ylabel('Genome Haploid Length (Mb)')

        # Add legend
        plt.legend()

        # Save the figure
        plt.savefig(output.genomescope_size_png)

        # Plot Model Fit min/max
        # Create the plot
        plt.figure(figsize=(10,6))
        plt.plot(df['Model Fit min'], label='min')
        plt.plot(df['Model Fit max'], label='max')

        # Add title and labels
        plt.title(f'Model fit {sample}_k{thisk}')
        plt.xlabel('Sample')
        plt.ylabel('Model fi')

        # Add legend
        plt.legend()

        # Save the figure
        plt.savefig(output.genomescope_fit_png)

rule run_sharkmer_viewer:
    input:
        histo = "output/{sample}_k{thisk}.sharkmer.histo",
        stats = "output/{sample}_k{thisk}.sharkmer.stats",
    output:
        sharkmer_viewer_plot = "output/{sample}_k{thisk}.sharkmer_view.html",
        sharkmer_genome_plot = "output/{sample}_k{thisk}.sharkmer_view_genome_size.html",
    params:
        sample = lambda wildcards: wildcards.sample,
        thisk = lambda wildcards: wildcards.thisk,
        base_name = "output/{sample}_k{thisk}.sharkmer_view",
    threads: workflow.cores
    shell:
        """
        sharkmer_viewer -d {input.histo} -s {input.stats}  -n {params.sample} -o {params.base_name}
        """

rule final_report:
    input:
        expand("output/{sample}_k{thisk}_jellyfish_summary.txt", sample = config["sample"], thisk = target_kmers),
        expand("output/{sample}.count", sample = config["sample"], thisk = target_kmers)
    output:
        report = "output/genome_size_report.tsv"
    run:
    
        import pandas as pd
    
        list_of_results = []
        for this_sample in config["sample"]:
            for this_kmer in target_kmers:
                
                targetfile = "output/{}_k{}_jellyfish_summary.txt".format(this_sample, this_kmer)
                with open(targetfile, "r") as f:
                #with open(input[0], "r") as f:
                    dict_of_vals = {}
                    dict_of_vals["sample"] = this_sample
                    dict_of_vals["ploidy"] = 2
                    dict_of_vals["k"] = this_kmer
                    start_count = False
                    counter = 0
                    for line in f:
                        line = line.strip()
                        if line:
                            splitd = line.split()
                            if splitd[0] == "property":
                                start_count = True
                            if start_count:
                                if counter == 1:
                                    dict_of_vals["min_hom"] = float(splitd[2].strip("%"))
                                    dict_of_vals["max_hom"] = float(splitd[3].strip("%"))
                                elif counter == 2:
                                    dict_of_vals["min_het"] = float(splitd[2].strip("%"))
                                    dict_of_vals["max_het"] = float(splitd[3].strip("%"))
                                elif counter == 3:
                                    dict_of_vals["min_hap_len"] =  splitd[3].replace("," , "")
                                    dict_of_vals["max_hap_len"] =  splitd[5].replace("," , "")
                                elif counter == 4:
                                    dict_of_vals["min_rep_len"] =  splitd[3].replace("," , "")
                                    dict_of_vals["max_rep_len"] =  splitd[5].replace("," , "")
                                elif counter == 5:
                                    dict_of_vals["min_uniq_len"] = splitd[3].replace("," , "")
                                    dict_of_vals["max_uniq_len"] = splitd[5].replace("," , "")
                                elif counter == 6:
                                    dict_of_vals["min_model_fit"] = float(splitd[2].strip("%"))
                                    dict_of_vals["max_model_fit"] = float(splitd[3].strip("%"))
                                elif counter == 7:
                                    dict_of_vals["min_read_error_rate"] = float(splitd[3].strip("%"))
                                    dict_of_vals["max_read_error_rate"] = float(splitd[4].strip("%"))
                                counter += 1
                    list_of_results.append(dict_of_vals)
        
        # Read the counts data
        list_of_counts = []
        for this_sample in config["sample"]:
            count_file = f"output/{this_sample}.count"
            with open(count_file, "r") as f:
                dict_of_counts = {}
                for line in f:
                    key, value = line.strip().split("\t")
                    dict_of_counts[key] = int(value)
                list_of_counts.append(dict_of_counts)

        # Merge results with counts data
        for result, counts in zip(list_of_results, list_of_counts):
            result.update(counts)
        
        df = pd.DataFrame(list_of_results)
        df.to_csv(output.report, sep="\t")
